{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating spark session\n",
    "spark = SparkSession.builder.appName('sentimentAnalysis').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_data = spark.read.parquet(os.path.join(DATA_DIR, 'train.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- data_prep: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- count_vect: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_processed_train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test some parameters, so we can chose the ones we will use int the model afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 581 ms, total: 2.97 s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "rdc = LogisticRegression()\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(rdc.maxIter, [5, 10, 15])\\\n",
    "                              .addGrid(rdc.regParam, [0.0001, 0.001, 0.0005])\\\n",
    "                              .addGrid(rdc.elasticNetParam, [0.2, 0.3, 0.4])\\\n",
    "                              .build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "valid = TrainValidationSplit(estimator = rdc,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator = evaluator,\n",
    "                             trainRatio = 0.50)\n",
    "model = valid.fit(pre_processed_train_data)\n",
    "best_model = model.bestModel\n",
    "result = best_model.transform(pre_processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result):\n",
    "    predictionAndLabels = result\n",
    "    metrics = [\"areaUnderROC\",\"areaUnderPR\"]\n",
    "    for m in metrics:\n",
    "        evaluator = BinaryClassificationEvaluator(metricName=m)\n",
    "        print(str(m) + \": \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.7853881807440036\n",
      "areaUnderPR: 0.7817562182134117\n"
     ]
    }
   ],
   "source": [
    "evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_6595ef6781f7', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.3,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='maxIter', doc='maximum number of iterations (>= 0)'): 10,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='regParam', doc='regularization parameter (>= 0)'): 0.001,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.5,\n",
       " Param(parent='LogisticRegression_6595ef6781f7', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='seed', doc='random seed.'): 1215852686270291499,\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='estimator', doc='estimator to be cross-validated'): LogisticRegression_34e71a7cd7bf,\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}],\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): BinaryClassificationEvaluator_7518c2f6664f}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 906kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/carolinaabs/Library/Caches/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 🏆 The winner parameters are: maxIter = 10 regParam = 0.001 elasticNetParam = 0.3 !!!! 🏆 \n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.emojize(' :trophy: The winner parameters are: maxIter = 10 regParam = 0.001 elasticNetParam = 0.3 !!!! :trophy: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_data = spark.read.parquet(os.path.join(DATA_DIR, 'test.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(training_df, testing_df):\n",
    "    \"\"\"\n",
    "    Apply Logistic Regression Classifier to test data for predicting sentiment of Tweets.\n",
    "    :param training_df: Trained labelled data\n",
    "    :param testing_df: Test data\n",
    "    :return: transformed dataframe of predicted labels for tweets\n",
    "    \"\"\"\n",
    "    lor = LogisticRegression(regParam = 0.001, maxIter = 10, elasticNetParam = 0.3)\n",
    "    model = lor.fit(training_df.drop('features').withColumnRenamed('count_vect', 'features'))\n",
    "    return model.transform(testing_df.drop('features').withColumnRenamed('count_vect', 'features')), model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr, summary = logistic_regression_classifier(pre_processed_train_data, pre_processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(result_df):\n",
    "    \"\"\"\n",
    "    Generate Confusion Matrix for showing the performance of algorithm.\n",
    "    :param result_df: Dataframe returned from the model\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    true_positives = result_df.filter((result_df.label == 1.0) & (result_df.prediction == 1.0)).count()\n",
    "    true_negatives = result_df.filter((result_df.label == 0.0) & (result_df.prediction == 0.0)).count()\n",
    "    false_positives = result_df.filter((result_df.label == 0.0) & (result_df.prediction == 1.0)).count()\n",
    "    false_negatives = result_df.filter((result_df.label == 1.0) & (result_df.prediction == 0.0)).count()\n",
    "\n",
    "    matrix = {\"Positive\": pd.Series([true_positives, false_positives], index=[\"Positive\", \"Negative\"]),\n",
    "              \"Negative\": pd.Series([false_negatives, true_negatives], index=[\"Positive\", \"Negative\"])}\n",
    "\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df.columns.name = \"Actual / Predicted\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual / Predicted</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>204013</td>\n",
       "      <td>36138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>107265</td>\n",
       "      <td>132456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual / Predicted  Positive  Negative\n",
       "Positive              204013     36138\n",
       "Negative              107265    132456"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(result_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(result_df):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of model against actual data.\n",
    "    :param result_df: Dataframe returned from the model\n",
    "    :return: accuracy between 0 and 1\n",
    "    \"\"\"\n",
    "    return 1.0 * result_df.filter(result_df.label == result_df.prediction).count() / result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701164060416111"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(result_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.788047461328519"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pr = summary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Model optimization**\n",
    "* If we imagine that we are designing this model for use in a company application, we know that the company does *not* want positive reviews to be categorized as negative. That is, we want to have as few **false positives** as possible. \n",
    "* On the other hand, if our manager <img src='notebook_ims/manager.jpg' width=8% /> asks for an application that will catch almost *all* cases of negative reviews, even if it means a higher number of false positives, then we'd want as few **false negatives** as possible.\n",
    "* To train according to specific product demands and goals, we do not want to optimize for accuracy only. Instead, we want to optimize for a metric that can help us decrease the number of false positives or negatives. \n",
    "\n",
    "<img src='notebook_ims/precision_recall.png' width=40% />\n",
    "     \n",
    "\n",
    "**2. Imbalanced training data**\n",
    "* At the start of this notebook, we saw that about 10 % of the data was labeled as false negatives. So, even if a model labels **all** of our data as valid, it will still have a poor accuracy. \n",
    "* This may result in some overfitting towards valid data, which accounts for some **false negatives**; cases in which negative reviews (0) are incorrectly characterized as positive (1).\n",
    "\n",
    "So, let's address these issues in order; first, tuning our model and optimizing for a specific metric during training, and second, accounting for class imbalance in the training set. \n",
    "\n",
    "**Scenario:**\n",
    "* A company has asked you to build a model that detects cases of positive reviews with an accuracy of about 85%. \n",
    "\n",
    "In this case, we want to build a model that has as many true positives and as few false negatives, as possible. This corresponds to a model with a high **recall**: true positives / (true positives + false negatives). \n",
    "\n",
    "HOW TO DO IT USING SPARK?\n",
    "\n",
    "I will assume that performance on a training set will be within about 5% of the performance on a test set. So, for a recall of about 85%, I'll aim for a bit higher, 90%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
