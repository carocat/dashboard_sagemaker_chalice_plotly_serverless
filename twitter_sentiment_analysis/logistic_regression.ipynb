{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating spark session\n",
    "spark = SparkSession.builder.appName('sentimentAnalysis').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train_data = spark.read.parquet(os.path.join(DATA_DIR, 'train_n2_25000.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- data_prep: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- count_vect: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_processed_train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test some parameters, so we can chose the ones we will use int the model afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 311 ms, total: 1.48 s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "rdc = LogisticRegression()\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(rdc.maxIter, [5, 10, 15])\\\n",
    "                              .addGrid(rdc.regParam, [0.0001, 0.001, 0.0005])\\\n",
    "                              .addGrid(rdc.elasticNetParam, [0.2, 0.3, 0.4])\\\n",
    "                              .build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "valid = TrainValidationSplit(estimator = rdc,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator = evaluator,\n",
    "                             trainRatio = 0.50)\n",
    "model = valid.fit(pre_processed_train_data)\n",
    "best_model = model.bestModel\n",
    "result = best_model.transform(pre_processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.7647649987264917, 0.2352350012735082]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.4693901481183246, 0.5306098518816754]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.5981790542862395, 0.40182094571376054]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.44151971508332244, 0.5584802849166776]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.44151971508332244, 0.5584802849166776]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                probability  prediction\n",
       "0      0   [0.7647649987264917, 0.2352350012735082]         0.0\n",
       "1      0   [0.4693901481183246, 0.5306098518816754]         1.0\n",
       "2      0  [0.5981790542862395, 0.40182094571376054]         0.0\n",
       "3      0  [0.44151971508332244, 0.5584802849166776]         1.0\n",
       "4      0  [0.44151971508332244, 0.5584802849166776]         1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('label', 'probability', 'prediction').toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result):\n",
    "    predictionAndLabels = result\n",
    "    metrics = [\"areaUnderROC\",\"areaUnderPR\"]\n",
    "    for m in metrics:\n",
    "        evaluator = BinaryClassificationEvaluator(metricName=m)\n",
    "        print(str(m) + \": \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.6756835964976943\n",
      "areaUnderPR: 0.7350748803870176\n"
     ]
    }
   ],
   "source": [
    "evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_06847243edb2', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.3,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='maxIter', doc='maximum number of iterations (>= 0)'): 10,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_06847243edb2', name='regParam', doc='regularization parameter (>= 0)'): 0.001,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.5,\n",
       " Param(parent='LogisticRegression_06847243edb2', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='seed', doc='random seed.'): 1215852686270291499,\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='estimator', doc='estimator to be cross-validated'): LogisticRegression_34e71a7cd7bf,\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.001,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3},\n",
       "  {Param(parent='LogisticRegression_34e71a7cd7bf', name='maxIter', doc='max number of iterations (>= 0).'): 15,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='regParam', doc='regularization parameter (>= 0).'): 0.0005,\n",
       "   Param(parent='LogisticRegression_34e71a7cd7bf', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}],\n",
       " Param(parent='TrainValidationSplitModel_72e0bb3e2657', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): BinaryClassificationEvaluator_7518c2f6664f}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " üèÜ The winner parameters are: maxIter = 10 regParam = 0.001 elasticNetParam = 0.3 !!!! üèÜ \n"
     ]
    }
   ],
   "source": [
    "#!pip install emoji --upgrade\n",
    "import emoji\n",
    "print(emoji.emojize(' :trophy: The winner parameters are: maxIter = 10 regParam = 0.001 elasticNetParam = 0.3 !!!! :trophy: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_data = spark.read.parquet(os.path.join(DATA_DIR, 'test_n2_25000.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(training_df, testing_df):\n",
    "    \"\"\"\n",
    "    Apply Logistic Regression Classifier to test data for predicting sentiment of Tweets.\n",
    "    :param training_df: Trained labelled data\n",
    "    :param testing_df: Test data\n",
    "    :return: transformed dataframe of predicted labels for tweets\n",
    "    \"\"\"\n",
    "    lor = LogisticRegression(regParam = 0.001, maxIter = 10, elasticNetParam = 0.3)\n",
    "    model = lor.fit(training_df)\n",
    "    return model.transform(testing_df), model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 ms, sys: 7.96 ms, total: 41.7 ms\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_lr, summary = logistic_regression_classifier(pre_processed_train_data, pre_processed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's get some probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, when, col\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "prob_neg = udf(lambda v:float(v[0]),FloatType())\n",
    "prob_pos = udf(lambda v:float(v[1]),FloatType())\n",
    "\n",
    "probability_column = when(col('label') == 1, prob_pos('probability'))\\\n",
    "    .when(col('label') == 0, prob_neg('probability'))\n",
    "\n",
    "result_prob = result_lr.withColumn('probability', probability_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(result_df):\n",
    "    \"\"\"\n",
    "    Generate Confusion Matrix for showing the performance of algorithm.\n",
    "    :param result_df: Dataframe returned from the model\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    true_positives = result_df.filter((result_df.label == 1.0) & (result_df.prediction == 1.0)).count()\n",
    "    true_negatives = result_df.filter((result_df.label == 0.0) & (result_df.prediction == 0.0)).count()\n",
    "    false_positives = result_df.filter((result_df.label == 0.0) & (result_df.prediction == 1.0)).count()\n",
    "    false_negatives = result_df.filter((result_df.label == 1.0) & (result_df.prediction == 0.0)).count()\n",
    "\n",
    "    matrix = {\"Positive\": pd.Series([true_positives, false_positives], index=[\"Positive\", \"Negative\"]),\n",
    "              \"Negative\": pd.Series([false_negatives, true_negatives], index=[\"Positive\", \"Negative\"])}\n",
    "\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df.columns.name = \"Actual / Predicted\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual / Predicted</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>203379</td>\n",
       "      <td>36772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>101015</td>\n",
       "      <td>138706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual / Predicted  Positive  Negative\n",
       "Positive              203379     36772\n",
       "Negative              101015    138706"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(result_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual / Predicted</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>203379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0</td>\n",
       "      <td>138706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual / Predicted  Positive  Negative\n",
       "Positive              203379         0\n",
       "Negative                   0    138706"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(result_prob.where(col('probability') > 0.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just practising.....how I feel ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>or i just worry too much?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orlando Lost  The Series. Oh Well, Mayb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rinitis sucks!!!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UGHHHHHHHHHHHHHHHHHHHHHHHHHHHHH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fuck, fuck, fuuuuck!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOX!     Floyd was great, but relievers nee...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eh  must leave New Mexico and soon!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>please, can anyone give loads of money or v...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-- Meet your Meat http://bit.ly/15SSCI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hoegaarden, cheezits, and an episode of Dext...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I hope my bebe feels better</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I wanna be able to drive my car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shock loss to Sparks...bummer, @tmmcwilliams...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UVA baseball...   Come on boys you can do it</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>alice is beating be at my scooby doo board g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>and they KEEP on coming!   xox</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gooood night!!   must prepare for tomorrows ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http://bit.ly/18xobk Five Guys Locations Clo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i need to think of something else, first.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jonas day is almost over...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>my ear hurts.  i blame cheap-ass earrings fr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nothing....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>they dont have the JB CD anywhere in my town...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>#squaresp #squarespac #squarespace #trackle g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&amp;lt;3 GrAdUaTE 09&amp;lt;3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&amp;quot; Vandals paint swastikas on home of aut...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&amp;quot;It's raining again&amp;quot; (c) Supertramp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(mood i am in)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(unsure) (annoyed) http://plurk.com/p/1230lz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>at work... *tears*</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>aw my best friend isnt terrible!!!! I have do...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>babby i miss you</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>besides that great graduation day. I finaly m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>bringing my lovely back home. Sucks. Great da...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>bryan wants on right now. if i can get on whe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>bummer. .. what happened to wednesday nights??</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>but I want #mansdrew to last FOREVER.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>but at least Monday's over #squarespace</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>but i  love that show @ohai_audrey ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>but so sad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>but theres always tomorrow..</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>cheer me up;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>clouds are rolling in....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>cnt even use a single Twitter App!!!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>coco doesnt tweet anymore. viva la hole woman...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>come on AppStore Approval. its been almost 18...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>comfort foods shall be the death of me - ther...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>cramps suck your mothers balls! *mentally scr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>dad left for turkey already</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>dag just when i decide to throw that freak em...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>definately bedtime</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>devstateddd, my silly iphone deleted all my j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>did God give up on us?!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>dident die from the tornado ohh well lol√¢¬ô¬•</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>everyones drunk but me</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>failing at everything i should just give up n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>fcukk you!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>fed up and upset. i need some good nosh down ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>finding out the Hollywood Video i frequent, i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  prediction  label  \\\n",
       "0                   just practising.....how I feel ...         1.0      0   \n",
       "1                    or i just worry too much?                 1.0      0   \n",
       "2           Orlando Lost  The Series. Oh Well, Mayb...         1.0      0   \n",
       "3                                   rinitis sucks!!!!!         1.0      0   \n",
       "4                      UGHHHHHHHHHHHHHHHHHHHHHHHHHHHHH         1.0      0   \n",
       "5                                 fuck, fuck, fuuuuck!         1.0      0   \n",
       "6       SOX!     Floyd was great, but relievers nee...         1.0      0   \n",
       "7                  eh  must leave New Mexico and soon!         1.0      0   \n",
       "8       please, can anyone give loads of money or v...         1.0      0   \n",
       "9               -- Meet your Meat http://bit.ly/15SSCI         1.0      0   \n",
       "10     Hoegaarden, cheezits, and an episode of Dext...         1.0      0   \n",
       "11                         I hope my bebe feels better         1.0      0   \n",
       "12                     I wanna be able to drive my car         1.0      0   \n",
       "13     Shock loss to Sparks...bummer, @tmmcwilliams...         1.0      0   \n",
       "14        UVA baseball...   Come on boys you can do it         1.0      0   \n",
       "15     alice is beating be at my scooby doo board g...         1.0      0   \n",
       "16                      and they KEEP on coming!   xox         1.0      0   \n",
       "17     gooood night!!   must prepare for tomorrows ...         1.0      0   \n",
       "18     http://bit.ly/18xobk Five Guys Locations Clo...         1.0      0   \n",
       "19          i need to think of something else, first.          1.0      0   \n",
       "20                        jonas day is almost over...          1.0      0   \n",
       "21     my ear hurts.  i blame cheap-ass earrings fr...         1.0      0   \n",
       "22                                         nothing....         1.0      0   \n",
       "23     they dont have the JB CD anywhere in my town...         1.0      0   \n",
       "24    #squaresp #squarespac #squarespace #trackle g...         1.0      0   \n",
       "25                              &lt;3 GrAdUaTE 09&lt;3         1.0      0   \n",
       "26    &quot; Vandals paint swastikas on home of aut...         1.0      0   \n",
       "27       &quot;It's raining again&quot; (c) Supertramp         1.0      0   \n",
       "28                                      (mood i am in)         1.0      0   \n",
       "29        (unsure) (annoyed) http://plurk.com/p/1230lz         1.0      0   \n",
       "..                                                 ...         ...    ...   \n",
       "170                                 at work... *tears*         1.0      0   \n",
       "171   aw my best friend isnt terrible!!!! I have do...         1.0      0   \n",
       "172                                   babby i miss you         1.0      0   \n",
       "173   besides that great graduation day. I finaly m...         1.0      0   \n",
       "174   bringing my lovely back home. Sucks. Great da...         1.0      0   \n",
       "175   bryan wants on right now. if i can get on whe...         1.0      0   \n",
       "176     bummer. .. what happened to wednesday nights??         1.0      0   \n",
       "177              but I want #mansdrew to last FOREVER.         1.0      0   \n",
       "178            but at least Monday's over #squarespace         1.0      0   \n",
       "179             but i  love that show @ohai_audrey ...         1.0      0   \n",
       "180                                         but so sad         1.0      0   \n",
       "181                       but theres always tomorrow..         1.0      0   \n",
       "182                                       cheer me up;         1.0      0   \n",
       "183                          clouds are rolling in....         1.0      0   \n",
       "184             cnt even use a single Twitter App!!!!!         1.0      0   \n",
       "185   coco doesnt tweet anymore. viva la hole woman...         1.0      0   \n",
       "186   come on AppStore Approval. its been almost 18...         1.0      0   \n",
       "187   comfort foods shall be the death of me - ther...         1.0      0   \n",
       "188   cramps suck your mothers balls! *mentally scr...         1.0      0   \n",
       "189                        dad left for turkey already         1.0      0   \n",
       "190   dag just when i decide to throw that freak em...         1.0      0   \n",
       "191                                 definately bedtime         1.0      0   \n",
       "192   devstateddd, my silly iphone deleted all my j...         1.0      0   \n",
       "193                            did God give up on us?!         1.0      0   \n",
       "194        dident die from the tornado ohh well lol√¢¬ô¬•         1.0      0   \n",
       "195                             everyones drunk but me         1.0      0   \n",
       "196   failing at everything i should just give up n...         1.0      0   \n",
       "197                                         fcukk you!         1.0      0   \n",
       "198   fed up and upset. i need some good nosh down ...         1.0      0   \n",
       "199   finding out the Hollywood Video i frequent, i...         1.0      0   \n",
       "\n",
       "     probability  \n",
       "0       0.437099  \n",
       "1       0.437099  \n",
       "2       0.475250  \n",
       "3       0.437099  \n",
       "4       0.437099  \n",
       "5       0.467466  \n",
       "6       0.325152  \n",
       "7       0.493817  \n",
       "8       0.437099  \n",
       "9       0.437099  \n",
       "10      0.437099  \n",
       "11      0.437099  \n",
       "12      0.437099  \n",
       "13      0.328556  \n",
       "14      0.437099  \n",
       "15      0.437099  \n",
       "16      0.437099  \n",
       "17      0.437099  \n",
       "18      0.437099  \n",
       "19      0.460053  \n",
       "20      0.243779  \n",
       "21      0.437099  \n",
       "22      0.437099  \n",
       "23      0.437099  \n",
       "24      0.437099  \n",
       "25      0.437099  \n",
       "26      0.437099  \n",
       "27      0.437099  \n",
       "28      0.437099  \n",
       "29      0.437099  \n",
       "..           ...  \n",
       "170     0.437099  \n",
       "171     0.418564  \n",
       "172     0.437099  \n",
       "173     0.298201  \n",
       "174     0.088179  \n",
       "175     0.479643  \n",
       "176     0.437099  \n",
       "177     0.437099  \n",
       "178     0.437099  \n",
       "179     0.275037  \n",
       "180     0.437099  \n",
       "181     0.437099  \n",
       "182     0.437099  \n",
       "183     0.437099  \n",
       "184     0.458684  \n",
       "185     0.280385  \n",
       "186     0.437099  \n",
       "187     0.400840  \n",
       "188     0.437099  \n",
       "189     0.437099  \n",
       "190     0.320958  \n",
       "191     0.437099  \n",
       "192     0.437099  \n",
       "193     0.488677  \n",
       "194     0.437099  \n",
       "195     0.437099  \n",
       "196     0.437099  \n",
       "197     0.437099  \n",
       "198     0.364564  \n",
       "199     0.437099  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob.where(col('probability') < 0.51).select('text', 'prediction', 'label', 'probability').toPandas().head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My cell phone screen is dead.  Soooooooooo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO MORE SICKNESS. strike i say STRIKE! ohh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone went home. and not everyone was e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geez I'm feeling their pain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... have to go now ??? 13 more minutes   .....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.586964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feeeling like shit right now. I really want...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I didn't realize it was THAT deep. Geez giv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm SICK of bedtime battles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Really Dont Like Doing my Room Its So Borin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This magazine story just broke my heart at ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wondering why I feel like I do...I'll feel ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bye guys!!!! i'ma miss ya'll sooo sooo much...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i don't even know.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>not at ALL happy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>such a sad day.  Miss ya jax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I think I may be too friendly...lol... o wel...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I wanted to sleep in this morning but a mean...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RSL was at the Paley talk?! Now I'm even mor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Why Twitter will soon become obsolete? http:...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anyone have any advice on how to cope with a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hi nia im bored</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>idk wat 2 do who can i trust me im sorry 4 a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>well, I guess I knew it was going to break s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.674125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wth seriously keith.im not coming tmr.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>#1son is up getting sick. The poor guy hasn't...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&amp;quot;An unknown error occured (-4)&amp;quot;. uh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>*wishes she was at summer jam*</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>- Like I said, my back still fucking hurts an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>- thelovelybones: I plan on owning this √¢¬Ä¬¶do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>... i try... i try so hard... and i seem to g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>awww man. This suckd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>broken hearts will heal with time...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>but I don't want a boyfriend for the summer.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>can't believe this. my school officially suck...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.953831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>can't get it off my mind... &amp;lt;/3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>can't hear the reds game in the tunnel.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>can't sleep again</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>cough is horrible. hope it's the end of the c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.805072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>could not get to sync facebook and twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>couldn't find anything I wanted at Fry's that...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>couldn't find it</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.780115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>cuz I wanna go to the Shedd Aquarium..2mrw is...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>damn! didnt make on time and the border was c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>dana fritz is gone for a week. I miss her :/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>dang i feel like shit and those &amp;quot;Above t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>didn't get to meet bachmann, but her young te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>didnt get to go get my tat...there is alwayz ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>doesn't have contacts on &amp;amp; can't see ='(</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>don't make fun of a concerned friend!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>dont feel good ptosis ;)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>dont know whats wrong with me</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ehhh bad day</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>everyone from home is going to the beach toda...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>feeling down. reality is setting in. i know i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>feeling very down this friday morning... i ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>for the fact that *I* didn't get any work don...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.751362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>gonna miss at least the first half of the PT:...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>good bye eighth graders...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>got my grandmothers results back from the Hos...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>gotta be in brandon at 9:15 tomorrow for a do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  prediction  label  \\\n",
       "0        My cell phone screen is dead.  Soooooooooo...         0.0      0   \n",
       "1        NO MORE SICKNESS. strike i say STRIKE! ohh...         0.0      0   \n",
       "2        everyone went home. and not everyone was e...         0.0      0   \n",
       "3                          geez I'm feeling their pain         0.0      0   \n",
       "4       ... have to go now ??? 13 more minutes   .....         0.0      0   \n",
       "5       Feeeling like shit right now. I really want...         0.0      0   \n",
       "6       I didn't realize it was THAT deep. Geez giv...         0.0      0   \n",
       "7                       I'm SICK of bedtime battles            0.0      0   \n",
       "8       Really Dont Like Doing my Room Its So Borin...         0.0      0   \n",
       "9       This magazine story just broke my heart at ...         0.0      0   \n",
       "10      Wondering why I feel like I do...I'll feel ...         0.0      0   \n",
       "11      bye guys!!!! i'ma miss ya'll sooo sooo much...         0.0      0   \n",
       "12                                  i don't even know.         0.0      0   \n",
       "13                                    not at ALL happy         0.0      0   \n",
       "14                        such a sad day.  Miss ya jax         0.0      0   \n",
       "15     I think I may be too friendly...lol... o wel...         0.0      0   \n",
       "16     I wanted to sleep in this morning but a mean...         0.0      0   \n",
       "17     RSL was at the Paley talk?! Now I'm even mor...         0.0      0   \n",
       "18     Why Twitter will soon become obsolete? http:...         0.0      0   \n",
       "19     anyone have any advice on how to cope with a...         0.0      0   \n",
       "20                                     hi nia im bored         0.0      0   \n",
       "21     idk wat 2 do who can i trust me im sorry 4 a...         0.0      0   \n",
       "22     well, I guess I knew it was going to break s...         0.0      0   \n",
       "23              wth seriously keith.im not coming tmr.         0.0      0   \n",
       "24    #1son is up getting sick. The poor guy hasn't...         0.0      0   \n",
       "25    &quot;An unknown error occured (-4)&quot;. uh...         0.0      0   \n",
       "26                      *wishes she was at summer jam*         0.0      0   \n",
       "27    - Like I said, my back still fucking hurts an...         0.0      0   \n",
       "28    - thelovelybones: I plan on owning this √¢¬Ä¬¶do...         0.0      0   \n",
       "29    ... i try... i try so hard... and i seem to g...         0.0      0   \n",
       "..                                                 ...         ...    ...   \n",
       "170                               awww man. This suckd         0.0      0   \n",
       "171               broken hearts will heal with time...         0.0      0   \n",
       "172       but I don't want a boyfriend for the summer.         0.0      0   \n",
       "173   can't believe this. my school officially suck...         0.0      0   \n",
       "174                 can't get it off my mind... &lt;/3         0.0      0   \n",
       "175            can't hear the reds game in the tunnel.         0.0      0   \n",
       "176                                  can't sleep again         0.0      0   \n",
       "177   cough is horrible. hope it's the end of the c...         0.0      0   \n",
       "178         could not get to sync facebook and twitter         0.0      0   \n",
       "179   couldn't find anything I wanted at Fry's that...         0.0      0   \n",
       "180                                   couldn't find it         0.0      0   \n",
       "181   cuz I wanna go to the Shedd Aquarium..2mrw is...         0.0      0   \n",
       "182   damn! didnt make on time and the border was c...         0.0      0   \n",
       "183       dana fritz is gone for a week. I miss her :/         0.0      0   \n",
       "184   dang i feel like shit and those &quot;Above t...         0.0      0   \n",
       "185   didn't get to meet bachmann, but her young te...         0.0      0   \n",
       "186   didnt get to go get my tat...there is alwayz ...         0.0      0   \n",
       "187       doesn't have contacts on &amp; can't see ='(         0.0      0   \n",
       "188              don't make fun of a concerned friend!         0.0      0   \n",
       "189                           dont feel good ptosis ;)         0.0      0   \n",
       "190                      dont know whats wrong with me         0.0      0   \n",
       "191                                       ehhh bad day         0.0      0   \n",
       "192   everyone from home is going to the beach toda...         0.0      0   \n",
       "193   feeling down. reality is setting in. i know i...         0.0      0   \n",
       "194   feeling very down this friday morning... i ha...         0.0      0   \n",
       "195   for the fact that *I* didn't get any work don...         0.0      0   \n",
       "196   gonna miss at least the first half of the PT:...         0.0      0   \n",
       "197                         good bye eighth graders...         0.0      0   \n",
       "198   got my grandmothers results back from the Hos...         0.0      0   \n",
       "199   gotta be in brandon at 9:15 tomorrow for a do...         0.0      0   \n",
       "\n",
       "     probability  \n",
       "0       0.652139  \n",
       "1       0.600999  \n",
       "2       0.757374  \n",
       "3       0.817140  \n",
       "4       0.586964  \n",
       "5       0.979364  \n",
       "6       0.593721  \n",
       "7       0.884411  \n",
       "8       0.777511  \n",
       "9       0.948792  \n",
       "10      0.866207  \n",
       "11      0.813726  \n",
       "12      0.635609  \n",
       "13      0.545651  \n",
       "14      0.983155  \n",
       "15      0.567056  \n",
       "16      0.987552  \n",
       "17      0.764470  \n",
       "18      0.589559  \n",
       "19      0.533472  \n",
       "20      0.756675  \n",
       "21      0.840835  \n",
       "22      0.674125  \n",
       "23      0.768769  \n",
       "24      0.996834  \n",
       "25      0.609864  \n",
       "26      0.867115  \n",
       "27      0.616153  \n",
       "28      0.529868  \n",
       "29      0.831930  \n",
       "..           ...  \n",
       "170     0.868127  \n",
       "171     0.794661  \n",
       "172     0.827090  \n",
       "173     0.953831  \n",
       "174     0.862459  \n",
       "175     0.732128  \n",
       "176     0.931269  \n",
       "177     0.805072  \n",
       "178     0.824205  \n",
       "179     0.895868  \n",
       "180     0.780115  \n",
       "181     0.578790  \n",
       "182     0.922521  \n",
       "183     0.612304  \n",
       "184     0.850498  \n",
       "185     0.848065  \n",
       "186     0.822397  \n",
       "187     0.902470  \n",
       "188     0.542753  \n",
       "189     0.743227  \n",
       "190     0.686270  \n",
       "191     0.860289  \n",
       "192     0.821449  \n",
       "193     0.974388  \n",
       "194     0.539544  \n",
       "195     0.751362  \n",
       "196     0.883787  \n",
       "197     0.769687  \n",
       "198     0.823149  \n",
       "199     0.579572  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob.where(col('probability') > 0.51).select('text', 'prediction', 'label', 'probability').toPandas().head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(result_df):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of model against actual data.\n",
    "    :param result_df: Dataframe returned from the model\n",
    "    :return: accuracy between 0 and 1\n",
    "    \"\"\"\n",
    "    return 1.0 * result_df.filter(result_df.label == result_df.prediction).count() / result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7128671812483329"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(result_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 0.8069099742103283\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc = summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr = summary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Model optimization**\n",
    "* If we imagine that we are designing this model for use in a company application, we know that the company does *not* want positive reviews to be categorized as negative. That is, we want to have as few **false positives** as possible. \n",
    "* On the other hand, if our manager <img src='notebook_ims/manager.jpg' width=8% /> asks for an application that will catch almost *all* cases of negative reviews, even if it means a higher number of false positives, then we'd want as few **false negatives** as possible.\n",
    "* To train according to specific product demands and goals, we do not want to optimize for accuracy only. Instead, we want to optimize for a metric that can help us decrease the number of false positives or negatives. \n",
    "\n",
    "<img src='notebook_ims/precision_recall.png' width=40% />\n",
    "     \n",
    "\n",
    "**2. Imbalanced training data**\n",
    "* At the start of this notebook, we saw that about 10 % of the data was labeled as false negatives. So, even if a model labels **all** of our data as valid, it will still have a poor accuracy. \n",
    "* This may result in some overfitting towards valid data, which accounts for some **false negatives**; cases in which negative reviews (0) are incorrectly characterized as positive (1).\n",
    "\n",
    "So, let's address these issues in order; first, tuning our model and optimizing for a specific metric during training, and second, accounting for class imbalance in the training set. \n",
    "\n",
    "**Scenario:**\n",
    "* A company has asked you to build a model that detects cases of positive reviews with an accuracy of about 85%. \n",
    "\n",
    "In this case, we want to build a model that has as many true positives and as few false negatives, as possible. This corresponds to a model with a high **recall**: true positives / (true positives + false negatives). \n",
    "\n",
    "HOW TO DO IT USING SPARK?\n",
    "\n",
    "I will assume that performance on a training set will be within about 5% of the performance on a test set. So, for a recall of about 85%, I'll aim for a bit higher, 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
